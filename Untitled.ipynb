{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc0e188-eed7-400c-9855-eedd1f4e2df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CON3ADOLEA\\.conda\\envs\\user\\lib\\site-packages\\lightfm\\_lightfm_fast.py:10: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  \"LightFM was compiled without OpenMP support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]\n",
      "LightFM version: 1.16\n"
     ]
    }
   ],
   "source": [
    "#data preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#import seaborn as sns\n",
    "\n",
    "#############################\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "import lightfm\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import cross_validation\n",
    "\n",
    "# Import LightFM's evaluation metrics\n",
    "from lightfm.evaluation import precision_at_k as lightfm_prec_at_k\n",
    "from lightfm.evaluation import recall_at_k as lightfm_recall_at_k\n",
    "\n",
    "# Import repo's evaluation metrics\n",
    "from recommenders.evaluation.python_evaluation import (\n",
    "    precision_at_k, recall_at_k)\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "#from recommenders.datasets import movielens\n",
    "from recommenders.models.lightfm.lightfm_utils import (\n",
    "    track_model_metrics, prepare_test_df, prepare_all_predictions,\n",
    "    compare_metric, similar_users, similar_items)\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"LightFM version: {}\".format(lightfm.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9798238a-0511-4c42-b460-24b6937b283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ratings_Electronics.csv') # load the dataset\n",
    "df=pd.DataFrame(df)\n",
    "df.columns = [\"userID\",\"itemID\",\"rating\",\"timestamp\"] #adding column head, convert rating into purchase\n",
    "df_product_1 = pd.DataFrame({'clicks':df.groupby('itemID').count()['rating'], 'Purchase':df.groupby('itemID').mean()['rating']})\n",
    "df['product_name']=df['itemID'].factorize()[0]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff8e0532-456b-4c66-9179-90f8b99b93e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default number of recommendations\n",
    "K = 20\n",
    "# percentage of data used for testing\n",
    "TEST_PERCENTAGE = 0.25\n",
    "# model learning rate\n",
    "LEARNING_RATE = 0.25\n",
    "# no of latent factors\n",
    "NO_COMPONENTS = 20\n",
    "# no of epochs to fit model\n",
    "NO_EPOCHS = 20\n",
    "# no of threads to fit model\n",
    "NO_THREADS = 32\n",
    "# regularisation for both user and item features\n",
    "ITEM_ALPHA=1e-6\n",
    "USER_ALPHA=1e-6\n",
    "\n",
    "# seed for pseudonumber generations\n",
    "SEEDNO = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b031a1a-544b-4401-bf33-a037c2c94c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of ratings are\t7824481\n",
      "Total number of users are\t4201696\n",
      "Total number of items are\t476001\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Total number of ratings are\\t{}\".format(df.shape[0]),\n",
    "    \"Total number of users are\\t{}\".format(df['userID'].nunique()),\n",
    "    \"Total number of items are\\t{}\".format(df['itemID'].nunique()),\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1597df0-93d5-4dac-8b7e-129c1221c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df['timestamp'].iloc[lambda x: x.index % 1 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f821bb10-0b6e-4b24-89c4-dd0bf3c2607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2= pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86bc60d5-e462-4ae0-bce1-bfa2606de9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "df['date']=df_2['timestamp'].apply(lambda t: datetime.utcfromtimestamp(t).strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe12167f-2cec-44ba-a673-20bbb9ab5cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>product_name</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2CX7LUOHB2NDG</td>\n",
       "      <td>0321732944</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1341100800</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-07-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2NWSAGRHCP8N5</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1367193600</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-04-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2WNBOD3WNDNKT</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1374451200</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-07-22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1GI0U4ZRJA8WN</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1334707200</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-04-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1QGNMC6O1VW39</td>\n",
       "      <td>0511189877</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1397433600</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userID      itemID  rating   timestamp  product_name  \\\n",
       "0  A2CX7LUOHB2NDG  0321732944     5.0  1341100800             1   \n",
       "1  A2NWSAGRHCP8N5  0439886341     1.0  1367193600             2   \n",
       "2  A2WNBOD3WNDNKT  0439886341     3.0  1374451200             2   \n",
       "3  A1GI0U4ZRJA8WN  0439886341     1.0  1334707200             2   \n",
       "4  A1QGNMC6O1VW39  0511189877     5.0  1397433600             3   \n",
       "\n",
       "                  date  \n",
       "0  2012-07-01 00:00:00  \n",
       "1  2013-04-29 00:00:00  \n",
       "2  2013-07-22 00:00:00  \n",
       "3  2012-04-18 00:00:00  \n",
       "4  2014-04-14 00:00:00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67a5c4cb-0231-44ed-b600-1bd7fb7c8843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[[3]], axis=1, inplace=True)# drop fourth column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42552526-efd1-4c78-a2c9-7debb3440b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>product_name</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2CX7LUOHB2NDG</td>\n",
       "      <td>0321732944</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-07-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2NWSAGRHCP8N5</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-04-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2WNBOD3WNDNKT</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-07-22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1GI0U4ZRJA8WN</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-04-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1QGNMC6O1VW39</td>\n",
       "      <td>0511189877</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userID      itemID  rating  product_name                 date\n",
       "0  A2CX7LUOHB2NDG  0321732944     5.0             1  2012-07-01 00:00:00\n",
       "1  A2NWSAGRHCP8N5  0439886341     1.0             2  2013-04-29 00:00:00\n",
       "2  A2WNBOD3WNDNKT  0439886341     3.0             2  2013-07-22 00:00:00\n",
       "3  A1GI0U4ZRJA8WN  0439886341     1.0             2  2012-04-18 00:00:00\n",
       "4  A1QGNMC6O1VW39  0511189877     5.0             3  2014-04-14 00:00:00"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1fb6d4f-6772-436c-bc01-1c2b894a6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset for training\n",
    "from recommenders.utils.spark_utils import start_or_get_spark\n",
    "from recommenders.datasets.download_utils import maybe_download\n",
    "from recommenders.datasets.python_splitters import python_random_split,python_chrono_split,python_stratified_split\n",
    "\n",
    "from recommenders.datasets.spark_splitters import spark_random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8389df7-537c-4951-9cad-7e930c1138b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5477136, 2347345)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = python_random_split(df, ratio=0.7)\n",
    "df_train.shape[0], df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "138cab6a-10e1-496d-8276-1d6b7187a877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>product_name</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4554563</th>\n",
       "      <td>ABWLJDWC6QCC6</td>\n",
       "      <td>B004XJI5L0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1305244800</td>\n",
       "      <td>249437</td>\n",
       "      <td>2011-05-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820602</th>\n",
       "      <td>A2TRTNDJ2J975S</td>\n",
       "      <td>B0019EHU8G</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1328054400</td>\n",
       "      <td>102804</td>\n",
       "      <td>2012-02-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444051</th>\n",
       "      <td>AQBM7P0N7X5H5</td>\n",
       "      <td>B004SUO068</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1366070400</td>\n",
       "      <td>242771</td>\n",
       "      <td>2013-04-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397666</th>\n",
       "      <td>A2UORC985H4Q2C</td>\n",
       "      <td>B0001IVB1S</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1370044800</td>\n",
       "      <td>24762</td>\n",
       "      <td>2013-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184182</th>\n",
       "      <td>A24THH2H7DYSLN</td>\n",
       "      <td>B003AJXUTQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1327017600</td>\n",
       "      <td>173084</td>\n",
       "      <td>2012-01-20 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 userID      itemID  rating   timestamp  product_name  \\\n",
       "4554563   ABWLJDWC6QCC6  B004XJI5L0     3.0  1305244800        249437   \n",
       "1820602  A2TRTNDJ2J975S  B0019EHU8G     5.0  1328054400        102804   \n",
       "4444051   AQBM7P0N7X5H5  B004SUO068     4.0  1366070400        242771   \n",
       "397666   A2UORC985H4Q2C  B0001IVB1S     5.0  1370044800         24762   \n",
       "3184182  A24THH2H7DYSLN  B003AJXUTQ     5.0  1327017600        173084   \n",
       "\n",
       "                        date  \n",
       "4554563  2011-05-13 00:00:00  \n",
       "1820602  2012-02-01 00:00:00  \n",
       "4444051  2013-04-16 00:00:00  \n",
       "397666   2013-06-01 00:00:00  \n",
       "3184182  2012-01-20 00:00:00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc1f9b5-d267-4857-bffb-49f0016e48dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>product_name</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1157290</th>\n",
       "      <td>AKEDGA2LY445V</td>\n",
       "      <td>B000M9ISQ2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1187740800</td>\n",
       "      <td>68354</td>\n",
       "      <td>2007-08-22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677500</th>\n",
       "      <td>AEFTIUQHSVUFX</td>\n",
       "      <td>B002L6HE9G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1363392000</td>\n",
       "      <td>146910</td>\n",
       "      <td>2013-03-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5814179</th>\n",
       "      <td>A15LOGO6NBSI6B</td>\n",
       "      <td>B007MXGG5Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1358640000</td>\n",
       "      <td>319642</td>\n",
       "      <td>2013-01-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239750</th>\n",
       "      <td>A23LX12CA3G4FG</td>\n",
       "      <td>B008HOEDYU</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1385337600</td>\n",
       "      <td>345427</td>\n",
       "      <td>2013-11-25 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5344315</th>\n",
       "      <td>A3TV7QFYXAG130</td>\n",
       "      <td>B0069R7TAM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1402963200</td>\n",
       "      <td>293927</td>\n",
       "      <td>2014-06-17 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 userID      itemID  rating   timestamp  product_name  \\\n",
       "1157290   AKEDGA2LY445V  B000M9ISQ2     5.0  1187740800         68354   \n",
       "2677500   AEFTIUQHSVUFX  B002L6HE9G     1.0  1363392000        146910   \n",
       "5814179  A15LOGO6NBSI6B  B007MXGG5Q     5.0  1358640000        319642   \n",
       "6239750  A23LX12CA3G4FG  B008HOEDYU     1.0  1385337600        345427   \n",
       "5344315  A3TV7QFYXAG130  B0069R7TAM     5.0  1402963200        293927   \n",
       "\n",
       "                        date  \n",
       "1157290  2007-08-22 00:00:00  \n",
       "2677500  2013-03-16 00:00:00  \n",
       "5814179  2013-01-20 00:00:00  \n",
       "6239750  2013-11-25 00:00:00  \n",
       "5344315  2014-06-17 00:00:00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12619632-6eab-4efe-9c29-29ecd11d5f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build hybrid recommendation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b5662b7-9970-431e-a729-ca9da32d2dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating user and item mapping\n",
    "#fit the model\n",
    "dataset = Dataset()\n",
    "dataset.fit(users=df['userID'],items=df['itemID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deb90b3f-cf1d-46ec-9430-3b9956e20c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 4201696, num_topics: 476001.\n"
     ]
    }
   ],
   "source": [
    "# quick check to determine the number of unique users and items in the data\n",
    "num_users, num_topics = dataset.interactions_shape()\n",
    "print(f'Num users: {num_users}, num_topics: {num_topics}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d69f27e-2d38-492d-a7aa-3569d0797faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next is to build the interaction matrix. The build_interactions method returns 2 COO sparse matrices, namely the interactions and weights matrices\n",
    "(interactions, weights) = dataset.build_interactions(df.iloc[:, 0:3].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74806c1b-3de5-4db8-8850-934c841f140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interactions, test_interactions = cross_validation.random_train_test_split(\n",
    "    interactions, test_percentage=TEST_PERCENTAGE,\n",
    "    random_state=np.random.RandomState(SEEDNO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef723873-5c35-466c-aecb-c4023fc2b1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train interactions: (4201696, 476001)\n",
      "Shape of test interactions: (4201696, 476001)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of train interactions: {train_interactions.shape}\")\n",
    "print(f\"Shape of test interactions: {test_interactions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84417471-9db0-43c8-8079-1966fccf6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the LightFM model\n",
    "model1 = LightFM(loss='warp', no_components=NO_COMPONENTS, \n",
    "                 learning_rate=LEARNING_RATE,                 \n",
    "                 random_state=np.random.RandomState(SEEDNO))\n",
    "\n",
    "model1.fit(interactions=train_interactions,epochs=NO_EPOCHS);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a8225b-b45e-4775-bb1c-101879a75b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the model evaluation data\n",
    "#uids, iids, interaction_data = cross_validation._shuffle(\n",
    "#    interactions.row, interactions.col, interactions.data, \n",
    "#    random_state=np.random.RandomState(SEEDNO))\n",
    "\n",
    "#cutoff = int((1.0 - TEST_PERCENTAGE) * len(uids))\n",
    "#test_idx = slice(cutoff, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ab86ec-0c76-4497-bf1d-03911352d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then the the mapping between internal and external representation of the user and item are extracted as follows\n",
    "#uid_map, ufeature_map, iid_map, ifeature_map = dataset.mapping()\n",
    "\n",
    "\n",
    "#Once the train/test indices and mapping are ready, the test dataframe can be constructed as follows\n",
    "#with Timer() as test_time:\n",
    "#    test_df = prepare_test_df(test_idx, uids, iids, uid_map, iid_map, weights)\n",
    "#print(f\"Took {test_time.interval:.1f} seconds for prepare and predict test data.\")  \n",
    "#time_reco1 = test_time.interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1128ef36-a65c-4a0d-862f-d835684f2fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d58f175f-4d70-400a-aa6a-f35ae686ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_precision = lightfm_prec_at_k(model1, train_interactions, k=20).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "092fc6aa-2d48-4d7c-b7b0-5ff34045516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_precision = lightfm_prec_at_k(model1, test_interactions, k=20,train_interactions = train_interactions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7225f865-8e09-47b0-b960-7b17ab9ffa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_auc = auc_score(model1, train_interactions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f61332a-ab3f-4c17-bc38-a207dc44f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_auc = auc_score(model1, test_interactions, train_interactions = train_interactions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af705d5d-da86-4b6a-889d-5b3be9e30a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.00, test 0.00.\n",
      "AUC: train 0.63, test 0.69.\n"
     ]
    }
   ],
   "source": [
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e772dcf-dd4a-4e6a-b019-52b7398b8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1, _ = track_model_metrics(model=model1, train_interactions=train_interactions, \n",
    "                              test_interactions=test_interactions, k=K,\n",
    "                              no_epochs=NO_EPOCHS, no_threads=NO_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51550639-10c3-4e58-998b-b99eb6b57e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a45bf-db28-40b7-896f-b95daade8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"this stores the values in all pages\"\"\"\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "import shutil\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "page = 1\n",
    "title = []\n",
    "_links=[]\n",
    "im_link =[]\n",
    "image_info = []\n",
    "\n",
    "dimension = [] #dimension of the artwork\n",
    "date_created =[] #date artwork was created\n",
    "artwork_origin =[] #artwork origin\n",
    "medium = [] #artwork medium\n",
    "decript_aut=[]#details about author\n",
    "artwork_artist=[] #artist name\n",
    "artwork_dept=[] #artwork department\n",
    "title_artwork=[] # artwork title\n",
    "date_released=[] # date artwork was released\n",
    "aut_life=[] #authors name and time lived\n",
    "\n",
    "def getdata(url): \n",
    "    r = requests.get(url) \n",
    "    return r.text\n",
    "\n",
    "while page != 60:\n",
    "    url = f\"https://www.artic.edu/collection?is_public_domain=1&page={page}\"\n",
    "    #print(url)\n",
    "    response = requests.get(url)\n",
    "    html = response.content\n",
    "    soup = bs(html, \"html.parser\")\n",
    "        \n",
    "    for all_title in soup.find_all('strong', class_=\"title f-list-7\"):\n",
    "        tit=all_title.get_text() ##provides the title of the art work in image_url\n",
    "        title.append(tit)\n",
    "    \n",
    "    for a in soup.find_all('a',class_=\"m-listing__link\"):\n",
    "        image_tag = a.findChildren(\"img\")\n",
    "        image_tilt=a.findChildren(\"strong\",class_=\"title f-list-7\")\n",
    "        for i in image_tilt:\n",
    "            v=random.randint(3, 9)\n",
    "            if i == None:\n",
    "                i.append(v)\n",
    "            else:\n",
    "                #image_info.append(i.get_text())\n",
    "                z=(image_tag[0][\"data-pin-media\"],i.get_text())\n",
    "            #print(image_tag[0][\"data-pin-media\"])\n",
    "            #print(image_info)\n",
    "            image_info.append(z)\n",
    "            \n",
    "    for item_t in soup.find_all('span'):\n",
    "        images = item_t.find_all('img', {'data-pin-media':re.compile('.jpg')})\n",
    "        for image in images:\n",
    "            image_url=((image['data-pin-media']+'\\n')) #provides the image link to download with 600 size\n",
    "            im_link.append(image_url)\n",
    "        #print(image_url)\n",
    "    \n",
    "    def download_image(image_info):\n",
    "        response = requests.get(image_info[0], stream=True)\n",
    "        realname = ''.join(e for e in image_info[1] if e.isalnum())\n",
    "        file = open(\"./10000/{}.jpg\".format(realname), 'wb')\n",
    "        response.raw.decode_content = True\n",
    "        shutil.copyfileobj(response.raw, file)\n",
    "        del response\n",
    "    \n",
    "    \n",
    "    \n",
    "    for all_links in soup.find_all('a',class_=\"m-listing__link\"):\n",
    "        links=(all_links['href']) ##provide link to webpage for each item\n",
    "        _links.append(links)\n",
    "    #print(_links)\n",
    "    \n",
    "    for all_link in _links:\n",
    "        cont_page= requests.get(all_link)\n",
    "        htmls = cont_page.content\n",
    "        sou= BeautifulSoup(htmls,\"html.parser\")\n",
    "        for item_t in sou.find_all('p',class_=\"title f-secondary o-article__inline-header-display\")[:-1]:\n",
    "            datx=(item_t.get_text()) ## obtain date artwork was released\n",
    "            date_released.append(datx)\n",
    "        \n",
    "        for item_t in sou.find_all('p',class_=\"title f-secondary o-article__inline-header-display\")[1:]:\n",
    "            daty=(item_t.get_text()) ##obtain author life on earth\n",
    "            aut_life.append(daty)\n",
    "        \n",
    "        for item_t in sou.find_all('span', class_ =\"title f-headline-editorial o-article__inline-header-title\"):\n",
    "            title_artwork.append(item_t.get_text()) ##artwork title\n",
    "        \n",
    "        for item_t in sou.find_all('ul', class_=\"list list--inline f-secondary\"):        \n",
    "            artwork_dept.append(item_t.get_text()) ## artwork department\n",
    "        \n",
    "        for item_t in sou.find_all('div',class_=\"o-blocks\"):\n",
    "            for i in list([item_t.find_all('p')[0:][:-2]]):\n",
    "                if i == []:\n",
    "                    [x for x in i if x]\n",
    "                else:\n",
    "                    decript_aut.append(i)\n",
    "                        \n",
    "        for item_t in sou.find_all('dl', class_=\"deflist o-blocks__block\"):\n",
    "            for nex in item_t.find_all('dd')[0]:\n",
    "                #print(nex.get_text())\n",
    "                if nex == '\\n':\n",
    "                    [x for x in nex if x]\n",
    "                else:\n",
    "                    d=[]\n",
    "                    d.append(nex.get_text())\n",
    "                    rem_n1 = [x[1:] for x in d]\n",
    "                    rem_n = [x[:-1] for x in rem_n1]\n",
    "                    artwork_artist.append(rem_n) ### artist name\n",
    "                        \n",
    "            for n in item_t.find_all('dd')[2]:\n",
    "                if n == '\\n':\n",
    "                    [x for x in n if x]\n",
    "                else:\n",
    "                    artwork_origin.append(n.get_text()) ##artwork origin\n",
    "                        \n",
    "            for e in item_t.find_all('dd')[3]:\n",
    "                #print(nex.get_text())\n",
    "                if e == '\\n':\n",
    "                    [x for x in e if x]\n",
    "                else:\n",
    "                    c=[]\n",
    "                    c.append(e.get_text())\n",
    "                    rem_n1 = [x[1:] for x in c]\n",
    "                    rem_n = [x[:-1] for x in rem_n1]\n",
    "                    date_created.append(rem_n) ### date artwork was created\n",
    "                \n",
    "            for cex in item_t.find_all('dd')[4]:\n",
    "                if cex == '\\n':\n",
    "                    [x for x in cex if x]\n",
    "                else:\n",
    "                    medium.append(cex.get_text()) ##artwork medium\n",
    "                        \n",
    "            for cx in item_t.find_all('dd')[5]:\n",
    "                if cx == '\\n':\n",
    "                    [x for x in cx if x]\n",
    "                else:\n",
    "                    dimension.append(cx.get_text()) ##artwork dimension\n",
    "        \n",
    "        \n",
    "    page = page + 1\n",
    "    \n",
    "    \n",
    "#f=(title,artwork_artist,im_link,_links,title_artwork,\n",
    "#   date_released,aut_life,artwork_dept,dimension,\n",
    "#   date_created,artwork_origin,medium,decript_aut) ##merging the arrays\n",
    "#print(f)\n",
    "#df_ = pd.DataFrame(f,index = [\"title\",\"authors_name\",\"image_link\",\"image_webpage\",\"artwork_title\",\n",
    "#                              \"date_released\",\"authors_name_and_age\",\"artwork_department\",\"dimension\",\n",
    "#                             \"date_created\",\"artwork_origin\",\"artwork_medium\",\"artwork_description\"])#\n",
    "f=(title_artwork,date_released,aut_life,artwork_dept,dimension,date_created,artwork_origin,medium,title,artwork_artist)\n",
    "df_ = pd.DataFrame(f,index = [\"artwork_title\",\"date_released\",\"authors_name_and_age\",\n",
    "                              \"artwork_department\",\"dimension\",\"date_created\",\"artwork_origin\",\n",
    "                              \"artwork_medium\",\"title\",\"authors_name\"])\n",
    "data_set=pd.DataFrame(df_.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64eb18d-1489-4a97-98e3-62e273bac484",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"this stores the values in all pages\"\"\"\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "import shutil\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "title = []\n",
    "_links=[]\n",
    "im_link =[]\n",
    "image_info = []\n",
    "\n",
    "dimension = [] #dimension of the artwork\n",
    "date_created =[] #date artwork was created\n",
    "artwork_origin =[] #artwork origin\n",
    "medium = [] #artwork medium\n",
    "decript_aut=[]#details about author\n",
    "artwork_artist=[] #artist name\n",
    "artwork_dept=[] #artwork department\n",
    "title_artwork=[] # artwork title\n",
    "date_released=[] # date artwork was released\n",
    "aut_life=[] #authors name and time lived\n",
    "\n",
    "def getdata(url): \n",
    "    r = requests.get(url) \n",
    "    return r.text\n",
    "\n",
    "page = 1\n",
    "url = f\"https://www.artic.edu/collection?is_public_domain=1&page={page}\"\n",
    "#print(url)\n",
    "response = requests.get(url)\n",
    "html = response.content\n",
    "soup = bs(html, \"html.parser\")\n",
    "        \n",
    "for all_title in soup.find_all('strong', class_=\"title f-list-7\"):\n",
    "    tit=all_title.get_text() ##provides the title of the art work in image_url\n",
    "    title.append(tit)\n",
    "    \n",
    "for a in soup.find_all('a',class_=\"m-listing__link\"):\n",
    "    image_tag = a.findChildren(\"img\")\n",
    "    image_tilt=a.findChildren(\"strong\",class_=\"title f-list-7\")\n",
    "        \n",
    "    for i in image_tilt:\n",
    "        v=random.randint(3, 9)\n",
    "        if i == None:\n",
    "            print(i.append(v))\n",
    "        else:\n",
    "            #image_info.append(i.get_text())\n",
    "            for c in image_tag:\n",
    "                cd=c[\"data-pin-media\"]\n",
    "                z=(cd,i.get_text())\n",
    "                image_info.append(z)\n",
    "\n",
    "            \n",
    "for item_t in soup.find_all('span'):\n",
    "    images = item_t.find_all('img', {'data-pin-media':re.compile('.jpg')})\n",
    "    for image in images:\n",
    "        image_url=((image['data-pin-media']+'\\n')) #provides the image link to download with 600 size\n",
    "        im_link.append(image_url)\n",
    "    #print(image_url)\n",
    "    \n",
    "    \n",
    "for all_links in soup.find_all('a',class_=\"m-listing__link\"):\n",
    "    links=(all_links['href']) ##provide link to webpage for each item\n",
    "    _links.append(links)\n",
    "#print(_links)\n",
    "    \n",
    "for all_link in _links:\n",
    "    cont_page= requests.get(all_link)\n",
    "    htmls = cont_page.content\n",
    "    sou= BeautifulSoup(htmls,\"html.parser\")\n",
    "    for item_t in sou.find_all('p',class_=\"title f-secondary o-article__inline-header-display\")[:-1]:\n",
    "        datx=(item_t.get_text()) ## obtain date artwork was released\n",
    "        date_released.append(datx)\n",
    "        \n",
    "    for item_t in sou.find_all('p',class_=\"title f-secondary o-article__inline-header-display\")[1:]:\n",
    "        daty=(item_t.get_text()) ##obtain author life on earth\n",
    "        aut_life.append(daty)\n",
    "        \n",
    "    for item_t in sou.find_all('span', class_ =\"title f-headline-editorial o-article__inline-header-title\"):\n",
    "        title_artwork.append(item_t.get_text()) ##artwork title\n",
    "        \n",
    "    for item_t in sou.find_all('ul', class_=\"list list--inline f-secondary\"):        \n",
    "        artwork_dept.append(item_t.get_text()) ## artwork department\n",
    "        \n",
    "    for item_t in sou.find_all('div',class_=\"o-blocks\"):\n",
    "        for i in list([item_t.find_all('p')[0:][:-2]]):\n",
    "            if i == []:\n",
    "                [x for x in i if x]\n",
    "            else:\n",
    "                decript_aut.append(i)\n",
    "                        \n",
    "    for item_t in sou.find_all('dl', class_=\"deflist o-blocks__block\"):\n",
    "        for nex in item_t.find_all('dd')[0]:\n",
    "            #print(nex.get_text())\n",
    "            if nex == '\\n':\n",
    "                [x for x in nex if x]\n",
    "            else:\n",
    "                d=[]\n",
    "                d.append(nex.get_text())\n",
    "                rem_n1 = [x[1:] for x in d]\n",
    "                rem_n = [x[:-1] for x in rem_n1]\n",
    "                artwork_artist.append(rem_n) ### artist name\n",
    "                        \n",
    "        for n in item_t.find_all('dd')[2]:\n",
    "            if n == '\\n':\n",
    "                [x for x in n if x]\n",
    "            else:\n",
    "                artwork_origin.append(n.get_text()) ##artwork origin\n",
    "                        \n",
    "        for e in item_t.find_all('dd')[3]:\n",
    "            #print(nex.get_text())\n",
    "            if e == '\\n':\n",
    "                [x for x in e if x]\n",
    "            else:\n",
    "                c=[]\n",
    "                c.append(e.get_text())\n",
    "                rem_n1 = [x[1:] for x in c]\n",
    "                rem_n = [x[:-1] for x in rem_n1]\n",
    "                date_created.append(rem_n) ### date artwork was created\n",
    "                \n",
    "        for cex in item_t.find_all('dd')[4]:\n",
    "            if cex == '\\n':\n",
    "                [x for x in cex if x]\n",
    "            else:\n",
    "                medium.append(cex.get_text()) ##artwork medium\n",
    "                        \n",
    "        for cx in item_t.find_all('dd')[5]:\n",
    "            if cx == '\\n':\n",
    "                [x for x in cx if x]\n",
    "            else:\n",
    "                dimension.append(cx.get_text()) ##artwork dimension\n",
    "\n",
    "f=(title,artwork_artist,title_artwork,date_released,aut_life,artwork_dept,dimension,date_created,artwork_origin,medium,image_info)\n",
    "df_ = pd.DataFrame(f,index = [\"title\",\"authors_name\",\n",
    "                              \"artwork_title\",\"date_released\",\n",
    "                              \"authors_name_and_age\",\"artwork_department\",\n",
    "                              \"dimension\",\"date_created\",\"artwork_origin\",\n",
    "                              \"artwork_medium\",\"image_information\"])\n",
    "\n",
    "dataset=pd.DataFrame(df_.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683d81a7-915b-4e80-86f6-23e07793bec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69501799-dccd-4d05-8444-a72e0cd0bb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
